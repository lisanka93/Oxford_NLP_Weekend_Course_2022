{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f90ddaf",
   "metadata": {},
   "source": [
    "lowercases everything\n",
    "Replaces email addresses with emailaddr\n",
    "Replaces URLs with httpaddr\n",
    "Replaces money symbols with moneysymb\n",
    "Replaces phone numbers with phonenumbr\n",
    "Replaces numbers with numbr (note: you will have to make a small change to the regular expression so it does not convert <3 into <numbr)\n",
    "Only deletes \"single\" punctuation when using the twitter tokeniser\n",
    "deletes stopwords (can be the ones from nltk)\n",
    "stemms all remaining words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd64778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "with open(\"stopword_file.txt\", 'r') as f:\n",
    "    stop_words.extend(f.read().splitlines())\n",
    "\n",
    "\n",
    "def preprocess_tweet(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    cleaned = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr ', text)\n",
    "    cleaned = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr ',\n",
    "                     cleaned)\n",
    "    cleaned = re.sub(r'£|\\$|\\€', 'moneysymb ', cleaned) \n",
    "    cleaned = re.sub(\n",
    "        r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "        'phonenumbr ', cleaned)\n",
    "    cleaned = re.sub(r'\\s\\d+(\\.\\d+)?', 'numbr ', cleaned)   #\\s added \n",
    " \n",
    "    \n",
    "    tokenised = tt.tokenize(cleaned)\n",
    "    \n",
    "    #trick - single letteres are usually considered stopwords and by default ignored by sklearns countvectorizer\n",
    "    #so no need to check whether a symbol is a letter or punctuation\n",
    "    # also - let's do three things at the same time instead of writing three separate loops\n",
    "    \n",
    "    tokenised_clean = []\n",
    "    \n",
    "    for i in tokenised:\n",
    "        if len(i) >= 2 and i not in stop_words:\n",
    "            tokenised_clean.append(stemmer.stem(i))\n",
    "            \n",
    "    final_output = \" \".join(tokenised_clean)\n",
    "    \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b3fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"This is a test checking @anonymous www.web.com that this works <3 :) ! 44 56\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070d7620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test check @anonym httpaddr work <3 :) numbr numbr'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweet(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4164281",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised = tt.tokenize(\"this is a test ! ! :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ae1741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test', '!', '!', ':)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60507b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qualimental_2] *",
   "language": "python",
   "name": "conda-env-qualimental_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
